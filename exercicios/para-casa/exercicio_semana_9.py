# -*- coding: utf-8 -*-
"""exercicio-semana-9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1btjKXTzlcROc7VpRtcmqhv-n8A8Y1igW
"""

# Importando as bibliotecas necessárias

import pandas as pd
import numpy as np

# Carregando o CSV com dados do meu estado (Bahia)

df = pd.read_csv('data_sample_BA.csv', sep=';' , encoding='latin-1', on_bad_lines='skip')

df

# 1. Calcular a média da temperatura da amostra

media_temperatura = df['TEMPERATURA DO AR - BULBO SECO. HORARIA (C)'].mean()
print(f"Média da temperatura: {media_temperatura:.2f} °C")

# 2. Retirar nulos da coluna 'RADIACAO GLOBAL (Kj/m2)'

df = df.dropna(subset=['RADIACAO GLOBAL (Kj/m2)'])
df.shape
df['RADIACAO GLOBAL (Kj/m2)']

# 3. Copiar o DataFrame reduzindo para 3 colunas e 1000 linhas aleatórias


colunas_selecionadas = ['TEMPERATURA DO AR - BULBO SECO. HORARIA (C)', 'RADIACAO GLOBAL (Kj/m2)', 'UMIDADE RELATIVA DO AR. HORARIA (%)']
df_reduzido = df[colunas_selecionadas].sample(n=1000, random_state=1)
df_reduzido = df_reduzido.reset_index(drop=True)

df_reduzido

# Bônus I: normalizar coluna (qualquer uma)
# Normalizar a coluna 'UMIDADE RELATIVA DO AR. HORARIA (%)'

df_normalizado = df.copy()

coluna = "UMIDADE RELATIVA DO AR. HORARIA (%)"

df_normalizado[coluna] = (df_normalizado[coluna] - df_normalizado[coluna].min()) / (df_normalizado[coluna].max() - df_normalizado[coluna].min())

df_normalizado[coluna]

"""## Bônus II: Pesquisar sobre outras formas de processamento de dados além das vistas em sala de aula




* Análise de componentes principais (PCA): Para redução de dimensionalidade;
* Filtragem de dados: Usando técnicas como suavização, filtragem de Kalman, etc;
* Transformação de dados: Como transformações logarítmicas ou exponenciais para dados não-lineares;
* Interpolação de dados: Preencher valores ausentes com métodos como interpolação linear ou polinomial;
* Agrupamento (Clustering): Algoritmos como K-means para segmentação de dados.
"""